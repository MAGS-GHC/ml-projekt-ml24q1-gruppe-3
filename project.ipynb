{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image parameters to the constants that we will use later for data re-shaping and for model traning.\n",
    "(_, IMAGE_WIDTH, IMAGE_HEIGHT) = x_train.shape\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "print('IMAGE_WIDTH:', IMAGE_WIDTH);\n",
    "print('IMAGE_HEIGHT:', IMAGE_HEIGHT);\n",
    "print('IMAGE_CHANNELS:', IMAGE_CHANNELS);\n",
    "\n",
    "\n",
    "pd.DataFrame(x_train[0])\n",
    "\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_display = 25\n",
    "num_cells = math.ceil(math.sqrt(numbers_to_display))\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(numbers_to_display):\n",
    "    plt.subplot(num_cells, num_cells, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_with_chanels = x_train.reshape(\n",
    "    x_train.shape[0],\n",
    "    IMAGE_WIDTH,\n",
    "    IMAGE_HEIGHT,\n",
    "    IMAGE_CHANNELS\n",
    ")\n",
    "\n",
    "x_test_with_chanels = x_test.reshape(\n",
    "    x_test.shape[0],\n",
    "    IMAGE_WIDTH,\n",
    "    IMAGE_HEIGHT,\n",
    "    IMAGE_CHANNELS\n",
    ")\n",
    "\n",
    "print('x_train_with_chanels:', x_train_with_chanels.shape)\n",
    "print('x_test_with_chanels:', x_test_with_chanels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = x_train_with_chanels / 255\n",
    "x_test_normalized = x_test_with_chanels / 255\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Convolution2D(\n",
    "    input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "    kernel_size=5,\n",
    "    filters=8,\n",
    "    strides=1,\n",
    "    activation=tf.keras.activations.relu,\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling()\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2)\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Convolution2D(\n",
    "    kernel_size=5,\n",
    "    filters=16,\n",
    "    strides=1,\n",
    "    activation=tf.keras.activations.relu,\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling()\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2)\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=128,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10,\n",
    "    activation=tf.keras.activations.softmax,\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling()\n",
    "))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "log_dir=\".logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "# Use the batch_size parameter in the fit method\n",
    "training_history = model.fit(\n",
    "    x_train_normalized,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test_normalized, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(training_history.history['loss'], label='training set')\n",
    "plt.plot(training_history.history['val_loss'], label='test set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(training_history.history['accuracy'], label='training set')\n",
    "plt.plot(training_history.history['val_accuracy'], label='test set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_loss, train_accuracy = model.evaluate(x_train_normalized, y_train)\n",
    "print('Training loss: ', train_loss)\n",
    "print('Training accuracy: ', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss, validation_accuracy = model.evaluate(x_test_normalized, y_test)\n",
    "print('Validation loss: ', validation_loss)\n",
    "print('Validation accuracy: ', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'digits_recognition_cnn.h5'\n",
    "model.save(model_name, save_format='h5')\n",
    "loaded_model = tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_one_hot = loaded_model.predict([x_test_normalized])\n",
    "print('predictions_one_hot:', predictions_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions_one_hot, axis=1)\n",
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test_normalized[0].reshape((IMAGE_WIDTH, IMAGE_HEIGHT)), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_display = 196\n",
    "num_cells = math.ceil(math.sqrt(numbers_to_display))\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for plot_index in range(numbers_to_display):    \n",
    "    predicted_label = predictions[plot_index]\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    color_map = 'Greens' if predicted_label == y_test[plot_index] else 'Reds'\n",
    "    plt.subplot(num_cells, num_cells, plot_index + 1)\n",
    "    plt.imshow(x_test_normalized[plot_index].reshape((IMAGE_WIDTH, IMAGE_HEIGHT)), cmap=color_map)\n",
    "    plt.xlabel(predicted_label)\n",
    "\n",
    "plt.subplots_adjust(hspace=1, wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n",
    "f, ax = plt.subplots(figsize=(9, 7))\n",
    "sn.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    linewidths=.5,\n",
    "    fmt=\"d\",\n",
    "    square=True,\n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZyklEQVR4nO3df0xV9/3H8dfF6vUXXESECxUt2la3qrSzyoittZMJLDP+itG2y7RpNDo0VdbZsLRauyXsa5Ou0TD9Z5M1qdqaVI1mNbFYcN3QTatjZh0TQytGwdUMLmJFJ5/vH8a7XoXai/fy5uLzkZxE7j0fzntnJzx7vNeLxznnBABAN4uzHgAAcG8iQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMR91gPcqr29XefOnVN8fLw8Ho/1OACAMDnn1NLSovT0dMXFdX6f0+MCdO7cOWVkZFiPAQC4S/X19Ro+fHinz/e4AMXHx0u6MXhCQoLxNACAcAUCAWVkZAR/nncmagEqLS3VG2+8oYaGBmVlZWnTpk2aPHnyHdfd/Gu3hIQEAgQAMexOL6NE5U0I7777roqKirRu3Tp98sknysrKUl5eni5cuBCNwwEAYlBUAvTmm29qyZIlev755/Xtb39bW7Zs0cCBA/W73/0uGocDAMSgiAfo6tWrOnbsmHJzc/93kLg45ebmqqqq6rb929raFAgEQjYAQO8X8QB98cUXun79ulJTU0MeT01NVUNDw237l5SUyOfzBTfeAQcA9wbzf4haXFys5ubm4FZfX289EgCgG0T8XXDJycnq06ePGhsbQx5vbGyU3++/bX+v1yuv1xvpMQAAPVzE74D69euniRMnqry8PPhYe3u7ysvLlZOTE+nDAQBiVFT+HVBRUZEWLVqkxx9/XJMnT9Zbb72l1tZWPf/889E4HAAgBkUlQAsWLNC///1vrV27Vg0NDXr00Ue1f//+296YAAC4d3mcc856iK8KBALy+Xxqbm7mkxAAIAZ905/j5u+CAwDcmwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJ+6wHABA9//rXv7q0bsyYMWGv2bhxY9hrVq5cGfYa9B7cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJvgwUqAXO378eJfWxcWF/9+m999/f5eOhXsXd0AAABMECABgIuIBeu211+TxeEK2sWPHRvowAIAYF5XXgB555BF9+OGH/zvIfbzUBAAIFZUy3HffffL7/dH41gCAXiIqrwGdOnVK6enpGjVqlJ577jmdOXOm033b2toUCARCNgBA7xfxAGVnZ6usrEz79+/X5s2bVVdXpyeffFItLS0d7l9SUiKfzxfcMjIyIj0SAKAHiniACgoKNH/+fE2YMEF5eXn6wx/+oKamJr333nsd7l9cXKzm5ubgVl9fH+mRAAA9UNTfHZCYmKiHH35YtbW1HT7v9Xrl9XqjPQYAoIeJ+r8DunTpkk6fPq20tLRoHwoAEEMiHqCXXnpJlZWV+uyzz/TnP/9Zc+bMUZ8+ffTMM89E+lAAgBgW8b+CO3v2rJ555hldvHhRw4YN0xNPPKHDhw9r2LBhkT4UACCGRTxAO3bsiPS3BNBFJ06c6NK6wYMHh71m7ty5XToW7l18FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLqv5AOQGT8/e9/D3vNpk2bunSsH//4x11aB4SDOyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4NOwgRhRU1MT9prW1tYuHWvBggVdWgeEgzsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEH0YKxIgNGzaEveaBBx7o0rEef/zxLq0DwsEdEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggg8jBQx89tlnYa/561//GvaaMWPGhL1GkgYNGtSldUA4uAMCAJggQAAAE2EH6NChQ5o5c6bS09Pl8Xi0e/fukOedc1q7dq3S0tI0YMAA5ebm6tSpU5GaFwDQS4QdoNbWVmVlZam0tLTD5zds2KCNGzdqy5YtOnLkiAYNGqS8vDxduXLlrocFAPQeYb8JoaCgQAUFBR0+55zTW2+9pVdeeUWzZs2SJL399ttKTU3V7t27tXDhwrubFgDQa0T0NaC6ujo1NDQoNzc3+JjP51N2draqqqo6XNPW1qZAIBCyAQB6v4gGqKGhQZKUmpoa8nhqamrwuVuVlJTI5/MFt4yMjEiOBADooczfBVdcXKzm5ubgVl9fbz0SAKAbRDRAfr9fktTY2BjyeGNjY/C5W3m9XiUkJIRsAIDeL6IByszMlN/vV3l5efCxQCCgI0eOKCcnJ5KHAgDEuLDfBXfp0iXV1tYGv66rq9OJEyeUlJSkESNGaNWqVfrlL3+phx56SJmZmXr11VeVnp6u2bNnR3JuAECMCztAR48e1dNPPx38uqioSJK0aNEilZWVac2aNWptbdXSpUvV1NSkJ554Qvv371f//v0jNzUAIOaFHaBp06bJOdfp8x6PR6+//rpef/31uxoM6M0qKyu75TjDhg3rluMAXWH+LjgAwL2JAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJsL+NGwAd6+6urpbjrNmzZpuOQ7QFdwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm+DBS4C5VVVWFvWbr1q1hr3nsscfCXvP9738/7DVAd+EOCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwYeRAnepvLw87DX/+c9/wl6Tn58f9pr+/fuHvQboLtwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm+DBS4C797W9/65bjzJ8/v1uOA3QX7oAAACYIEADARNgBOnTokGbOnKn09HR5PB7t3r075PnFixfL4/GEbF35PSYAgN4t7AC1trYqKytLpaWlne6Tn5+v8+fPB7ft27ff1ZAAgN4n7DchFBQUqKCg4Gv38Xq98vv9XR4KAND7ReU1oIqKCqWkpGjMmDFavny5Ll682Om+bW1tCgQCIRsAoPeLeIDy8/P19ttvq7y8XP/3f/+nyspKFRQU6Pr16x3uX1JSIp/PF9wyMjIiPRIAoAeK+L8DWrhwYfDP48eP14QJEzR69GhVVFRo+vTpt+1fXFysoqKi4NeBQIAIAcA9IOpvwx41apSSk5NVW1vb4fNer1cJCQkhGwCg94t6gM6ePauLFy8qLS0t2ocCAMSQsP8K7tKlSyF3M3V1dTpx4oSSkpKUlJSk9evXa968efL7/Tp9+rTWrFmjBx98UHl5eREdHAAQ28IO0NGjR/X0008Hv775+s2iRYu0efNmVVdX6/e//72ampqUnp6uGTNm6Be/+IW8Xm/kpgYAxDyPc85ZD/FVgUBAPp9Pzc3NvB6EbtfQ0BD2mkcffTTsNUOGDAl7zaeffhr2GsDCN/05zmfBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETEfyU3EMvKysrCXtPY2Bj2moKCgrDXAL0Nd0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+jBT4is8//7xbjjNkyJBuOQ7Qk3EHBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4MNIga/Yu3dvtxznhz/8YbccB+jJuAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEzwYaTolf74xz92aV1jY2OEJwHQGe6AAAAmCBAAwERYASopKdGkSZMUHx+vlJQUzZ49WzU1NSH7XLlyRYWFhRo6dKgGDx6sefPm8dcaAIDbhBWgyspKFRYW6vDhwzpw4ICuXbumGTNmqLW1NbjP6tWrtXfvXu3cuVOVlZU6d+6c5s6dG/HBAQCxLaw3Iezfvz/k67KyMqWkpOjYsWOaOnWqmpub9dvf/lbbtm3T9773PUnS1q1b9a1vfUuHDx/Wd7/73chNDgCIaXf1GlBzc7MkKSkpSZJ07NgxXbt2Tbm5ucF9xo4dqxEjRqiqqqrD79HW1qZAIBCyAQB6vy4HqL29XatWrdKUKVM0btw4SVJDQ4P69eunxMTEkH1TU1PV0NDQ4fcpKSmRz+cLbhkZGV0dCQAQQ7ocoMLCQp08eVI7duy4qwGKi4vV3Nwc3Orr6+/q+wEAYkOX/iHqihUrtG/fPh06dEjDhw8PPu73+3X16lU1NTWF3AU1NjbK7/d3+L28Xq+8Xm9XxgAAxLCw7oCcc1qxYoV27dqlgwcPKjMzM+T5iRMnqm/fviovLw8+VlNTozNnzignJycyEwMAeoWw7oAKCwu1bds27dmzR/Hx8cHXdXw+nwYMGCCfz6cXXnhBRUVFSkpKUkJCglauXKmcnBzeAQcACBFWgDZv3ixJmjZtWsjjW7du1eLFiyVJv/71rxUXF6d58+apra1NeXl5+s1vfhORYQEAvUdYAXLO3XGf/v37q7S0VKWlpV0eCrhbu3bt6tK6//73v2Gveeyxx8Je89RTT4W9Buht+Cw4AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOjSb0QFutPly5fDXvPBBx9EYZKOzZ8/P+w1ffr0icIkQGzhDggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMGHkaLH69u3b9hrEhMTu3SsWbNmhb3mxRdf7NKxgHsdd0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+jBQ9Xlc+jLSqqioKkwCIJO6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImwAlRSUqJJkyYpPj5eKSkpmj17tmpqakL2mTZtmjweT8i2bNmyiA4NAIh9YQWosrJShYWFOnz4sA4cOKBr165pxowZam1tDdlvyZIlOn/+fHDbsGFDRIcGAMS+sH4j6v79+0O+LisrU0pKio4dO6apU6cGHx84cKD8fn9kJgQA9Ep39RpQc3OzJCkpKSnk8XfeeUfJyckaN26ciouLdfny5U6/R1tbmwKBQMgGAOj9wroD+qr29natWrVKU6ZM0bhx44KPP/vssxo5cqTS09NVXV2tl19+WTU1NXr//fc7/D4lJSVav359V8cAAMQoj3POdWXh8uXL9cEHH+jjjz/W8OHDO93v4MGDmj59umprazV69Ojbnm9ra1NbW1vw60AgoIyMDDU3NyshIaErowEADAUCAfl8vjv+HO/SHdCKFSu0b98+HTp06GvjI0nZ2dmS1GmAvF6vvF5vV8YAAMSwsALknNPKlSu1a9cuVVRUKDMz845rTpw4IUlKS0vr0oAAgN4prAAVFhZq27Zt2rNnj+Lj49XQ0CBJ8vl8GjBggE6fPq1t27bpBz/4gYYOHarq6mqtXr1aU6dO1YQJE6LyPwAAEJvCeg3I4/F0+PjWrVu1ePFi1dfX60c/+pFOnjyp1tZWZWRkaM6cOXrllVe+8es53/TvDgEAPVNUXgO6U6syMjJUWVkZzrcEANyj+Cw4AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJ+6wHuJVzTpIUCASMJwEAdMXNn983f553pscFqKWlRZKUkZFhPAkA4G60tLTI5/N1+rzH3SlR3ay9vV3nzp1TfHy8PB5PyHOBQEAZGRmqr69XQkKC0YT2OA83cB5u4DzcwHm4oSecB+ecWlpalJ6erri4zl/p6XF3QHFxcRo+fPjX7pOQkHBPX2A3cR5u4DzcwHm4gfNwg/V5+Lo7n5t4EwIAwAQBAgCYiKkAeb1erVu3Tl6v13oUU5yHGzgPN3AebuA83BBL56HHvQkBAHBviKk7IABA70GAAAAmCBAAwAQBAgCYiJkAlZaW6oEHHlD//v2VnZ2tv/zlL9YjdbvXXntNHo8nZBs7dqz1WFF36NAhzZw5U+np6fJ4PNq9e3fI8845rV27VmlpaRowYIByc3N16tQpm2Gj6E7nYfHixbddH/n5+TbDRklJSYkmTZqk+Ph4paSkaPbs2aqpqQnZ58qVKyosLNTQoUM1ePBgzZs3T42NjUYTR8c3OQ/Tpk277XpYtmyZ0cQdi4kAvfvuuyoqKtK6dev0ySefKCsrS3l5ebpw4YL1aN3ukUce0fnz54Pbxx9/bD1S1LW2tiorK0ulpaUdPr9hwwZt3LhRW7Zs0ZEjRzRo0CDl5eXpypUr3TxpdN3pPEhSfn5+yPWxffv2bpww+iorK1VYWKjDhw/rwIEDunbtmmbMmKHW1tbgPqtXr9bevXu1c+dOVVZW6ty5c5o7d67h1JH3Tc6DJC1ZsiTketiwYYPRxJ1wMWDy5MmusLAw+PX169ddenq6KykpMZyq+61bt85lZWVZj2FKktu1a1fw6/b2duf3+90bb7wRfKypqcl5vV63fft2gwm7x63nwTnnFi1a5GbNmmUyj5ULFy44Sa6ystI5d+P/+759+7qdO3cG9/n000+dJFdVVWU1ZtTdeh6cc+6pp55yL774ot1Q30CPvwO6evWqjh07ptzc3OBjcXFxys3NVVVVleFkNk6dOqX09HSNGjVKzz33nM6cOWM9kqm6ujo1NDSEXB8+n0/Z2dn35PVRUVGhlJQUjRkzRsuXL9fFixetR4qq5uZmSVJSUpIk6dixY7p27VrI9TB27FiNGDGiV18Pt56Hm9555x0lJydr3LhxKi4u1uXLly3G61SP+zDSW33xxRe6fv26UlNTQx5PTU3VP//5T6OpbGRnZ6usrExjxozR+fPntX79ej355JM6efKk4uPjrccz0dDQIEkdXh83n7tX5Ofna+7cucrMzNTp06f185//XAUFBaqqqlKfPn2sx4u49vZ2rVq1SlOmTNG4ceMk3bge+vXrp8TExJB9e/P10NF5kKRnn31WI0eOVHp6uqqrq/Xyyy+rpqZG77//vuG0oXp8gPA/BQUFwT9PmDBB2dnZGjlypN577z298MILhpOhJ1i4cGHwz+PHj9eECRM0evRoVVRUaPr06YaTRUdhYaFOnjx5T7wO+nU6Ow9Lly4N/nn8+PFKS0vT9OnTdfr0aY0ePbq7x+xQj/8ruOTkZPXp0+e2d7E0NjbK7/cbTdUzJCYm6uGHH1Ztba31KGZuXgNcH7cbNWqUkpOTe+X1sWLFCu3bt08fffRRyK9v8fv9unr1qpqamkL2763XQ2fnoSPZ2dmS1KOuhx4foH79+mnixIkqLy8PPtbe3q7y8nLl5OQYTmbv0qVLOn36tNLS0qxHMZOZmSm/3x9yfQQCAR05cuSevz7Onj2rixcv9qrrwzmnFStWaNeuXTp48KAyMzNDnp84caL69u0bcj3U1NTozJkzvep6uNN56MiJEyckqWddD9bvgvgmduzY4bxerysrK3P/+Mc/3NKlS11iYqJraGiwHq1b/fSnP3UVFRWurq7O/elPf3K5ubkuOTnZXbhwwXq0qGppaXHHjx93x48fd5Lcm2++6Y4fP+4+//xz55xzv/rVr1xiYqLbs2ePq66udrNmzXKZmZnuyy+/NJ48sr7uPLS0tLiXXnrJVVVVubq6Ovfhhx+673znO+6hhx5yV65csR49YpYvX+58Pp+rqKhw58+fD26XL18O7rNs2TI3YsQId/DgQXf06FGXk5PjcnJyDKeOvDudh9raWvf666+7o0ePurq6Ordnzx43atQoN3XqVOPJQ8VEgJxzbtOmTW7EiBGuX79+bvLkye7w4cPWI3W7BQsWuLS0NNevXz93//33uwULFrja2lrrsaLuo48+cpJu2xYtWuScu/FW7FdffdWlpqY6r9frpk+f7mpqamyHjoKvOw+XL192M2bMcMOGDXN9+/Z1I0eOdEuWLOl1/5HW0f9+SW7r1q3Bfb788kv3k5/8xA0ZMsQNHDjQzZkzx50/f95u6Ci403k4c+aMmzp1qktKSnJer9c9+OCD7mc/+5lrbm62HfwW/DoGAICJHv8aEACgdyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPw/cto+VgUoYZYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to 1 with a 23.20 percent confidence.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9890\n",
      "3.4148842096328735 98.90000224113464\n",
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "index = 2\n",
    "score = tf.nn.softmax(predictions[index])\n",
    "\n",
    "# Save image parameters to the constants that we will use later for data re-shaping and for model traning.\n",
    "(_, IMAGE_WIDTH, IMAGE_HEIGHT) = x_test.shape\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "\n",
    "plt.imshow(x_test[index], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n",
    "t,t2 = model.evaluate(x_test_normalized,y_test)\n",
    "print(t*100,t2*100)\n",
    "\n",
    "model.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "4 0.7646341\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = load_model('test')\n",
    "\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    img.show()\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    \n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "\n",
    "        # Creating elements\n",
    "\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        digit, acc = predict_digit(im)\n",
    "        print(digit,acc)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=20\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
